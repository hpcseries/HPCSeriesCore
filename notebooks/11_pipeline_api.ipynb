{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPCSeries Pipeline API\n",
    "\n",
    "This notebook demonstrates the **Pipeline API** introduced in v0.8.0, which enables composable kernel execution for multi-stage data processing.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **12 predefined stages** for common time-series transformations\n",
    "- **Ping-pong buffer management** for efficient memory reuse\n",
    "- **Fluent API** for chaining operations\n",
    "- **Workspace support** for memory-intensive pipelines\n",
    "- **Three execution modes**: SAFE, FAST, DETERMINISTIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hpcs\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "print(f\"HPCSeries version: {hpcs.__version__}\")\n",
    "print(f\"Build features: {bin(hpcs.build_features())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Pipeline Usage\n",
    "\n",
    "Create a pipeline, add stages, and execute on input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample time series with trend, seasonality, and noise\n",
    "np.random.seed(42)\n",
    "n = 100_000\n",
    "t = np.arange(n)\n",
    "x = (\n",
    "    0.001 * t +                           # Trend\n",
    "    10 * np.sin(2 * np.pi * t / 1000) +   # Seasonality\n",
    "    np.random.randn(n)                    # Noise\n",
    ")\n",
    "\n",
    "# Inject some outliers\n",
    "outlier_idx = np.random.choice(n, size=50, replace=False)\n",
    "x[outlier_idx] += np.random.choice([-1, 1], size=50) * 20\n",
    "\n",
    "print(f\"Data shape: {x.shape}\")\n",
    "print(f\"Data range: [{x.min():.2f}, {x.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple pipeline\n",
    "pipe = hpcs.pipeline(mode='fast')\n",
    "\n",
    "# Add stages using fluent API\n",
    "pipe.diff(order=1)        # Remove trend with first differencing\n",
    "pipe.ewma(alpha=0.1)      # Smooth with exponential moving average\n",
    "pipe.robust_zscore()      # Normalize using MAD-based z-score\n",
    "\n",
    "# View pipeline summary\n",
    "print(pipe.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the pipeline\n",
    "start = time.perf_counter()\n",
    "result = pipe.execute(x)\n",
    "elapsed = time.perf_counter() - start\n",
    "\n",
    "print(f\"Pipeline execution time: {elapsed*1000:.2f} ms\")\n",
    "print(f\"Throughput: {n/elapsed/1e6:.2f} M elements/sec\")\n",
    "print(f\"Result shape: {result.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Available Pipeline Stages\n",
    "\n",
    "The pipeline supports 12 predefined operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate all available stages\n",
    "stages_info = [\n",
    "    (\"diff(order)\", \"Finite differencing: y[t] = x[t] - x[t-order]\"),\n",
    "    (\"ewma(alpha)\", \"Exponential weighted moving average\"),\n",
    "    (\"ewvar(alpha)\", \"Exponential weighted variance\"),\n",
    "    (\"ewstd(alpha)\", \"Exponential weighted standard deviation\"),\n",
    "    (\"rolling_mean(window)\", \"Rolling window mean\"),\n",
    "    (\"rolling_std(window)\", \"Rolling window standard deviation\"),\n",
    "    (\"rolling_median(window)\", \"Rolling window median (robust)\"),\n",
    "    (\"rolling_mad(window)\", \"Rolling window MAD (robust)\"),\n",
    "    (\"zscore()\", \"Global z-score normalization\"),\n",
    "    (\"robust_zscore(eps)\", \"MAD-based z-score (outlier resistant)\"),\n",
    "    (\"normalize_minmax()\", \"Scale to [0, 1] range\"),\n",
    "    (\"clip(min, max)\", \"Clamp values to range\"),\n",
    "]\n",
    "\n",
    "print(\"Available Pipeline Stages:\")\n",
    "print(\"=\" * 60)\n",
    "for stage, desc in stages_info:\n",
    "    print(f\"  {stage:30} - {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Execution Modes\n",
    "\n",
    "Three modes provide different trade-offs between safety and performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = ['safe', 'fast', 'deterministic']\n",
    "times = {}\n",
    "\n",
    "for mode in modes:\n",
    "    pipe = hpcs.pipeline(mode=mode)\n",
    "    pipe.diff(1).ewma(0.2).rolling_std(50).robust_zscore()\n",
    "    \n",
    "    # Warm-up\n",
    "    _ = pipe.execute(x)\n",
    "    \n",
    "    # Benchmark\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(10):\n",
    "        result = pipe.execute(x)\n",
    "    elapsed = (time.perf_counter() - start) / 10\n",
    "    times[mode] = elapsed\n",
    "\n",
    "print(\"Execution Mode Comparison:\")\n",
    "print(\"=\" * 50)\n",
    "for mode in modes:\n",
    "    speedup = times['safe'] / times[mode]\n",
    "    print(f\"  {mode:15} {times[mode]*1000:8.2f} ms  ({speedup:.2f}x vs safe)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Workspace for Large Arrays\n",
    "\n",
    "For memory-intensive operations, pre-allocate a workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create workspace (64MB)\n",
    "ws = hpcs.workspace(64 * 1024 * 1024)\n",
    "print(f\"Workspace size: {ws.size / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "# Use workspace with pipeline\n",
    "pipe = hpcs.pipeline(ws=ws, mode='fast')\n",
    "pipe.rolling_median(window=100)  # Memory-intensive operation\n",
    "pipe.robust_zscore()\n",
    "\n",
    "result = pipe.execute(x)\n",
    "print(f\"Result computed with workspace support\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grow workspace if needed\n",
    "ws.reserve(128 * 1024 * 1024)  # Grow to 128MB\n",
    "print(f\"Workspace grown to: {ws.size / 1024 / 1024:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pipeline vs Manual Chaining\n",
    "\n",
    "Compare pipeline execution to calling individual functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Pipeline (optimized buffer management)\n",
    "pipe = hpcs.pipeline(mode='fast')\n",
    "pipe.diff(1).ewma(0.2).zscore()\n",
    "\n",
    "start = time.perf_counter()\n",
    "for _ in range(100):\n",
    "    result_pipe = pipe.execute(x)\n",
    "time_pipe = (time.perf_counter() - start) / 100\n",
    "\n",
    "# Method 2: Manual chaining (extra allocations)\n",
    "start = time.perf_counter()\n",
    "for _ in range(100):\n",
    "    temp1 = hpcs.diff(x, order=1)\n",
    "    temp2 = hpcs.ewma(temp1, alpha=0.2)\n",
    "    result_manual = hpcs.zscore(temp2)\n",
    "time_manual = (time.perf_counter() - start) / 100\n",
    "\n",
    "print(f\"Pipeline:      {time_pipe*1000:.3f} ms\")\n",
    "print(f\"Manual chain:  {time_manual*1000:.3f} ms\")\n",
    "print(f\"Pipeline speedup: {time_manual/time_pipe:.2f}x\")\n",
    "print(f\"Results match: {np.allclose(result_pipe, result_manual, equal_nan=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Real-World Example: Anomaly Detection Pipeline\n",
    "\n",
    "Build a complete anomaly detection pipeline for sensor data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate sensor data with anomalies\n",
    "np.random.seed(123)\n",
    "n_sensors = 500_000\n",
    "sensor_data = np.cumsum(np.random.randn(n_sensors) * 0.1)  # Random walk\n",
    "sensor_data += 5 * np.sin(np.linspace(0, 50*np.pi, n_sensors))  # Seasonal\n",
    "\n",
    "# Inject anomalies (sudden spikes)\n",
    "anomaly_times = np.random.choice(n_sensors, size=100, replace=False)\n",
    "sensor_data[anomaly_times] += np.random.choice([-1, 1], size=100) * 10\n",
    "\n",
    "print(f\"Sensor readings: {n_sensors:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build anomaly detection pipeline\n",
    "anomaly_pipe = hpcs.pipeline(mode='fast')\n",
    "\n",
    "# Stage 1: Remove trend with differencing\n",
    "anomaly_pipe.diff(order=1)\n",
    "\n",
    "# Stage 2: Smooth short-term noise\n",
    "anomaly_pipe.ewma(alpha=0.3)\n",
    "\n",
    "# Stage 3: Compute robust z-scores\n",
    "anomaly_pipe.robust_zscore(eps=1e-10)\n",
    "\n",
    "print(anomaly_pipe.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute pipeline\n",
    "start = time.perf_counter()\n",
    "z_scores = anomaly_pipe.execute(sensor_data)\n",
    "elapsed = time.perf_counter() - start\n",
    "\n",
    "# Detect anomalies (|z| > 3)\n",
    "threshold = 3.0\n",
    "detected_anomalies = np.where(np.abs(z_scores) > threshold)[0]\n",
    "\n",
    "print(f\"Pipeline execution: {elapsed*1000:.2f} ms\")\n",
    "print(f\"Throughput: {n_sensors/elapsed/1e6:.2f} M readings/sec\")\n",
    "print(f\"Detected anomalies: {len(detected_anomalies)}\")\n",
    "print(f\"True anomalies injected: {len(anomaly_times)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Custom Pre/Post Processing\n",
    "\n",
    "The pipeline supports 12 predefined operations. For custom transformations, apply them before or after the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom pre-processing: log transform for skewed data\n",
    "x_raw = np.abs(np.random.randn(50_000)) + 0.1  # Positive, skewed\n",
    "x_log = np.log1p(x_raw)  # Custom: log(1+x) transform\n",
    "\n",
    "# Standard pipeline\n",
    "pipe = hpcs.pipeline(mode='fast')\n",
    "pipe.rolling_mean(window=20)\n",
    "pipe.zscore()\n",
    "result = pipe.execute(x_log)\n",
    "\n",
    "# Custom post-processing: convert to binary signal\n",
    "binary_signal = (np.abs(result) > 2.0).astype(float)\n",
    "\n",
    "print(f\"Flagged {binary_signal.sum():.0f} points as unusual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Discovery\n",
    "\n",
    "Query runtime information about the library build:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get build features bitmask\n",
    "features = hpcs.build_features()\n",
    "\n",
    "print(\"Build Features:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"  OpenMP:     {'Yes' if features & hpcs.FEAT_OPENMP else 'No'}\")\n",
    "print(f\"  AVX2:       {'Yes' if features & hpcs.FEAT_SIMD_AVX2 else 'No'}\")\n",
    "print(f\"  AVX-512:    {'Yes' if features & hpcs.FEAT_SIMD_AVX512 else 'No'}\")\n",
    "print(f\"  NEON:       {'Yes' if features & hpcs.FEAT_SIMD_NEON else 'No'}\")\n",
    "print(f\"  Fast Math:  {'Yes' if features & hpcs.FEAT_FAST_MATH else 'No'}\")\n",
    "print(f\"  GPU:        {'Yes' if features & hpcs.FEAT_GPU_OFFLOAD else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for errors (thread-local)\n",
    "error = hpcs.last_error()\n",
    "if error:\n",
    "    print(f\"Last error: {error}\")\n",
    "else:\n",
    "    print(\"No errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The Pipeline API provides:\n",
    "\n",
    "1. **Efficient Chaining**: Ping-pong buffers minimize allocations\n",
    "2. **12 Built-in Stages**: Common time-series transformations\n",
    "3. **Three Execution Modes**: SAFE (default), FAST, DETERMINISTIC\n",
    "4. **Workspace Support**: Pre-allocated memory for large arrays\n",
    "5. **Fluent API**: Readable method chaining\n",
    "\n",
    "For custom operations not in the 12 predefined stages, apply them before or after the pipeline using standard NumPy or individual HPCSeries functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
