{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPCSeries Core v0.8 - Getting Started\n",
    "\n",
    "Welcome to HPCSeries Core! This notebook provides a quick introduction to using the high-performance statistical computing library.\n",
    "\n",
    "## What is HPCSeries Core?\n",
    "\n",
    "HPCSeries Core is a high-performance statistical computing library that provides:\n",
    "- **SIMD-accelerated operations** for maximum performance\n",
    "- **Automatic parallelization** with OpenMP\n",
    "- **C/Fortran backend** for computationally intensive operations\n",
    "- **Python API** for ease of use\n",
    "- **Auto-tuning calibration** to optimize for your hardware\n",
    "\n",
    "## What's New in v0.8.0?\n",
    "\n",
    "**Exponential Weighted Statistics**:\n",
    "- `ewma()` - Exponentially weighted moving average\n",
    "- `ewvar()` - Exponentially weighted variance\n",
    "- `ewstd()` - Exponentially weighted standard deviation\n",
    "\n",
    "**Time Series Transforms**:\n",
    "- `diff()` - Time series differencing\n",
    "- `cumulative_min()`, `cumulative_max()` - Running extrema\n",
    "- `convolve_valid()` - FIR filtering\n",
    "\n",
    "**Advanced Robust Statistics**:\n",
    "- `trimmed_mean()` - Outlier-resistant mean\n",
    "- `winsorized_mean()` - Clamped mean\n",
    "\n",
    "## Installation\n",
    "\n",
    "```bash\n",
    "# Install in development mode\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "## Quick Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPCSeries Core version: 0.8.0\n",
      "\n",
      "Running CPU detection...\n",
      "=== CPU Information ===\n",
      "\n",
      "CPU Vendor:          AuthenticAMD\n",
      "Physical Cores:      4\n",
      "Logical Cores:       8\n",
      "Optimal Threads:     2\n",
      "\n",
      "Cache Hierarchy:\n",
      "  L1:      32 KB\n",
      "  L2:     512 KB\n",
      "  L3:    4096 KB\n",
      "\n",
      "NUMA Topology:\n",
      "  Nodes:               1\n",
      "  Cores per node:      4\n",
      "\n",
      "SIMD Capabilities:\n",
      "  Active ISA:          AVX2\n",
      "  Vector width:        256-bit (4 doubles)\n",
      "  SSE2:                ✓\n",
      "  AVX:                 ✓\n",
      "  AVX2:                ✓\n",
      "  AVX-512:             ✗\n",
      "  NEON:                ✗\n",
      "  FMA3:                ✓\n"
     ]
    }
   ],
   "source": [
    "import hpcs\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Display version and CPU info\n",
    "print(f\"HPCSeries Core version: {hpcs.__version__}\")\n",
    "print(\"\\nRunning CPU detection...\")\n",
    "!hpcs cpuinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Statistical Operations\n",
    "\n",
    "HPCSeries provides fast implementations of common statistical functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Statistics:\n",
      "Sum:      -692.499148\n",
      "Mean:     -0.000692\n",
      "Std Dev:  0.999580\n",
      "Variance: 0.999161\n",
      "Min:      -4.660955\n",
      "Max:      4.935668\n"
     ]
    }
   ],
   "source": [
    "# Create sample data\n",
    "data = np.random.randn(1_000_000)\n",
    "\n",
    "print(\"Basic Statistics:\")\n",
    "print(f\"Sum:      {hpcs.sum(data):.6f}\")\n",
    "print(f\"Mean:     {hpcs.mean(data):.6f}\")\n",
    "print(f\"Std Dev:  {hpcs.std(data):.6f}\")\n",
    "print(f\"Variance: {hpcs.var(data):.6f}\")\n",
    "print(f\"Min:      {hpcs.min(data):.6f}\")\n",
    "print(f\"Max:      {hpcs.max(data):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Robust Statistics\n",
    "\n",
    "Robust statistics are less sensitive to outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison: Regular vs Robust Statistics\n",
      "\n",
      "Mean:          -0.000692\n",
      "Median:        -0.000735\n",
      "\n",
      "Std Dev:       1.048407\n",
      "MAD (robust):  0.675018\n"
     ]
    }
   ],
   "source": [
    "# Add some outliers\n",
    "data_with_outliers = np.concatenate([data, [100, -100, 200, -200]])\n",
    "\n",
    "print(\"Comparison: Regular vs Robust Statistics\")\n",
    "print(f\"\\nMean:          {hpcs.mean(data_with_outliers):.6f}\")\n",
    "print(f\"Median:        {hpcs.median(data_with_outliers):.6f}\")\n",
    "print(f\"\\nStd Dev:       {hpcs.std(data_with_outliers):.6f}\")\n",
    "print(f\"MAD (robust):  {hpcs.mad(data_with_outliers):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Rolling Window Operations\n",
    "\n",
    "Compute statistics over sliding windows (C-accelerated rolling operations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed rolling statistics with window=50\n",
      "Output shape: (10000,)\n",
      "First 49 values are NaN (insufficient data)\n",
      "Valid values start at index 49\n"
     ]
    }
   ],
   "source": [
    "# Create time series data\n",
    "time_series = np.cumsum(np.random.randn(10000))\n",
    "window = 50\n",
    "\n",
    "# Rolling statistics\n",
    "rolling_mean = hpcs.rolling_mean(time_series, window)\n",
    "rolling_std = hpcs.rolling_std(time_series, window)\n",
    "rolling_median = hpcs.rolling_median(time_series, window)\n",
    "\n",
    "print(f\"Computed rolling statistics with window={window}\")\n",
    "print(f\"Output shape: {rolling_mean.shape}\")\n",
    "print(f\"First {window-1} values are NaN (insufficient data)\")\n",
    "print(f\"Valid values start at index {window-1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Z-Score Normalization (NEW in v0.7)\n",
    "\n",
    "Fast C-accelerated z-score computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling z-score computed (window=50)\n",
      "Mean of z-scores: 0.008271 (should be ~0)\n",
      "Std of z-scores:  1.377210 (should be ~1)\n"
     ]
    }
   ],
   "source": [
    "# Rolling z-score (C-optimized)\n",
    "rolling_zscore = hpcs.rolling_zscore(time_series, window)\n",
    "\n",
    "# Robust z-score using MAD\n",
    "rolling_robust_zscore = hpcs.rolling_robust_zscore(time_series, window)\n",
    "\n",
    "print(f\"Rolling z-score computed (window={window})\")\n",
    "print(f\"Mean of z-scores: {np.nanmean(rolling_zscore):.6f} (should be ~0)\")\n",
    "print(f\"Std of z-scores:  {np.nanstd(rolling_zscore):.6f} (should be ~1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance Comparison\n",
    "\n",
    "Let's compare HPCSeries with NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of 10,000,000 elements:\n",
      "  HPCSeries: 5.713 ms\n",
      "  NumPy:     7.058 ms\n",
      "  Speedup:   1.24x\n",
      "  Results match: True\n"
     ]
    }
   ],
   "source": [
    "# Large dataset for meaningful benchmarks\n",
    "large_data = np.random.randn(10_000_000)\n",
    "\n",
    "# Benchmark sum\n",
    "start = time.perf_counter()\n",
    "result_hpcs = hpcs.sum(large_data)\n",
    "time_hpcs = time.perf_counter() - start\n",
    "\n",
    "start = time.perf_counter()\n",
    "result_numpy = np.sum(large_data)\n",
    "time_numpy = time.perf_counter() - start\n",
    "\n",
    "print(f\"Sum of {len(large_data):,} elements:\")\n",
    "print(f\"  HPCSeries: {time_hpcs*1000:.3f} ms\")\n",
    "print(f\"  NumPy:     {time_numpy*1000:.3f} ms\")\n",
    "print(f\"  Speedup:   {time_numpy/time_hpcs:.2f}x\")\n",
    "print(f\"  Results match: {np.allclose(result_hpcs, result_numpy)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Auto-Tuning Calibration (NEW in v0.7)\n",
    "\n",
    "HPCSeries can automatically calibrate to your hardware for optimal performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running quick calibration...\n",
      "\n",
      "Calibration complete!\n",
      "Configuration saved to: /root/.hpcs/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=== HPCS Quick Calibration ===\n",
      "Running quick validation benchmark...\n",
      "  Sum (1M elements): 1004.00 µs\n",
      "Quick calibration complete (using hardware defaults).\n",
      "Run hpcs_calibrate() for full optimization.\n",
      "==============================\n",
      "[Config] Configuration saved to: /root/.hpcs/config.json\n"
     ]
    }
   ],
   "source": [
    "# Run quick calibration (5-10 seconds)\n",
    "print(\"Running quick calibration...\")\n",
    "hpcs.calibrate(quick=True)\n",
    "print(\"\\nCalibration complete!\")\n",
    "\n",
    "# Save configuration\n",
    "import os\n",
    "config_path = os.path.expanduser(\"~/.hpcs/config.json\")\n",
    "hpcs.save_calibration_config(config_path)\n",
    "print(f\"Configuration saved to: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. CLI Commands\n",
    "\n",
    "HPCSeries also provides a command-line interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPCSeries Core v0.8.0\n",
      "High-Performance Computing Series - Optimized Statistical Kernels\n",
      "\n",
      "Features:\n",
      "  • SIMD vectorization (AVX-512, AVX2, AVX, SSE2, NEON)\n",
      "  • OpenMP parallelization with NUMA awareness\n",
      "  • Adaptive auto-tuning (v0.5)\n",
      "  • Fortran/C/Python unified API\n",
      "=== CPU Information ===\n",
      "\n",
      "CPU Vendor:          AuthenticAMD\n",
      "Physical Cores:      4\n",
      "Logical Cores:       8\n",
      "Optimal Threads:     2\n",
      "\n",
      "Cache Hierarchy:\n",
      "  L1:      32 KB\n",
      "  L2:     512 KB\n",
      "  L3:    4096 KB\n",
      "\n",
      "NUMA Topology:\n",
      "  Nodes:               1\n",
      "  Cores per node:      4\n",
      "\n",
      "SIMD Capabilities:\n",
      "  Active ISA:          AVX2\n",
      "  Vector width:        256-bit (4 doubles)\n",
      "  SSE2:                ✓\n",
      "  AVX:                 ✓\n",
      "  AVX2:                ✓\n",
      "  AVX-512:             ✗\n",
      "  NEON:                ✗\n",
      "  FMA3:                ✓\n",
      "=== HPCSeries Auto-Tuning Calibration ===\n",
      "\n",
      "This will benchmark optimal parallelization thresholds for your system.\n",
      "\n",
      "Mode: quick calibration\n",
      "Estimated time: 5-10 seconds\n",
      "\n",
      "Running benchmarks...\n",
      "=== HPCS Quick Calibration ===\n",
      "Running quick validation benchmark...\n",
      "  Sum (1M elements): 725.00 µs\n",
      "Quick calibration complete (using hardware defaults).\n",
      "Run hpcs_calibrate() for full optimization.\n",
      "==============================\n",
      "✓ Calibration completed in 0.0s\n",
      "\n",
      "[Config] Configuration saved to: /root/.hpcs/config.json\n",
      "✓ Configuration saved to: /root/.hpcs/config.json\n",
      "\n",
      "Calibration complete! Optimal thresholds have been determined.\n",
      "These will be used automatically in future sessions.\n",
      "=== HPCSeries Performance Benchmark ===\n",
      "\n",
      "Array size:     1,000,000 elements (8.00 MB)\n",
      "Iterations:     5\n",
      "\n",
      "Generating test data...\n",
      "Running benchmarks...\n",
      "\n",
      "Function             Time (ms)    Throughput     \n",
      "--------------------------------------------------\n",
      "sum                     0.717      1394.84 M elem/s\n",
      "mean                    0.904      1106.25 M elem/s\n",
      "std                     1.646       607.48 M elem/s\n",
      "median                 17.717        56.44 M elem/s\n",
      "rolling_mean(50)        4.650       215.06 M elem/s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show version\n",
    "!hpcs version\n",
    "\n",
    "# Show CPU information\n",
    "!hpcs cpuinfo\n",
    "\n",
    "# Run quick calibration\n",
    "!hpcs calibrate --quick\n",
    "\n",
    "# Run benchmarks\n",
    "!hpcs bench --size 1000000 --iterations 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Explore more advanced features:\n",
    "\n",
    "1. **01_rolling_mean_vs_median.ipynb** - Rolling window operations\n",
    "2. **02_robust_anomaly_climate.ipynb** - Anomaly detection with robust statistics\n",
    "3. **03_batched_iot_rolling.ipynb** - Batched processing for IoT data\n",
    "4. **04_axis_reductions_column_stats.ipynb** - 2D array operations\n",
    "5. **05_masked_missing_data.ipynb** - Handling missing data\n",
    "6. **06_performance_calibration.ipynb** - Performance tuning and optimization\n",
    "7. **07_c_optimized_operations.ipynb** - C-accelerated operations (v0.7)\n",
    "8. **08_numpy_pandas_migration_guide.ipynb** - Migration from NumPy/Pandas\n",
    "9. **09_real_world_applications.ipynb** - Production use cases\n",
    "10. **10_exponential_weighted_statistics.ipynb** - Deep dive into EWMA/EWVAR/EWSTD (NEW in v0.8)\n",
    "\n",
    "## Documentation\n",
    "\n",
    "- **GitHub**: [HPCSeries Core Repository](https://github.com/yourusername/HPCSeriesCore)\n",
    "- **API Reference**: See `docs/` directory\n",
    "- **Specifications**: See root directory for detailed specs\n",
    "\n",
    "## Support\n",
    "\n",
    "For issues, questions, or contributions, please visit the GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIR Filtering with convolve_valid():\n",
      "  Input signal:  1000 points\n",
      "  Filter kernel: 3 points\n",
      "  Output:        998 points (no padding)\n",
      "  Formula: n - m + 1 = 1000 - 3 + 1 = 998\n"
     ]
    }
   ],
   "source": [
    "# FIR filtering with convolution\n",
    "signal = np.random.randn(1000)\n",
    "# 3-point moving average filter\n",
    "kernel = np.array([1/3, 1/3, 1/3])\n",
    "filtered = hpcs.convolve_valid(signal, kernel)\n",
    "\n",
    "print(f\"FIR Filtering with convolve_valid():\")\n",
    "print(f\"  Input signal:  {len(signal)} points\")\n",
    "print(f\"  Filter kernel: {len(kernel)} points\")\n",
    "print(f\"  Output:        {len(filtered)} points (no padding)\")\n",
    "print(f\"  Formula: n - m + 1 = {len(signal)} - {len(kernel)} + 1 = {len(filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Price Differencing:\n",
      "  Prices:  [100 102 101 105 103 107 110]\n",
      "  Changes: [nan  2. -1.  4. -2.  4.  3.]\n",
      "  Note: First value is NaN (no previous value to difference)\n",
      "\n",
      "Cumulative Extrema:\n",
      "  Values:     [5 3 7 2 8 1 9]\n",
      "  Cum Min:    [5. 3. 3. 2. 2. 1. 1.]\n",
      "  Cum Max:    [5. 5. 7. 7. 8. 8. 9.]\n"
     ]
    }
   ],
   "source": [
    "# Differencing - useful for making time series stationary\n",
    "stock_prices = np.array([100, 102, 101, 105, 103, 107, 110])\n",
    "price_changes = hpcs.diff(stock_prices, order=1)\n",
    "\n",
    "print(\"Stock Price Differencing:\")\n",
    "print(f\"  Prices:  {stock_prices}\")\n",
    "print(f\"  Changes: {price_changes}\")\n",
    "print(f\"  Note: First value is NaN (no previous value to difference)\")\n",
    "\n",
    "# Cumulative extrema - track running min/max\n",
    "values = np.array([5, 3, 7, 2, 8, 1, 9])\n",
    "cum_min = hpcs.cumulative_min(values)\n",
    "cum_max = hpcs.cumulative_max(values)\n",
    "\n",
    "print(f\"\\nCumulative Extrema:\")\n",
    "print(f\"  Values:     {values}\")\n",
    "print(f\"  Cum Min:    {cum_min}\")\n",
    "print(f\"  Cum Max:    {cum_max}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Time Series Transforms (NEW in v0.8)\n",
    "\n",
    "Transform time series data with differencing, cumulative operations, and filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alpha' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Exponential weighted variance and std dev\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ewvar_result \u001b[38;5;241m=\u001b[39m hpcs\u001b[38;5;241m.\u001b[39mewvar(large_data, \u001b[43malpha\u001b[49m)\n\u001b[1;32m      3\u001b[0m ewstd_result \u001b[38;5;241m=\u001b[39m hpcs\u001b[38;5;241m.\u001b[39mewstd(large_data, alpha)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExponential Weighted Variance and Std Dev:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'alpha' is not defined"
     ]
    }
   ],
   "source": [
    "# Exponential weighted variance and std dev\n",
    "ewvar_result = hpcs.ewvar(ts_data, alpha)\n",
    "ewstd_result = hpcs.ewstd(ts_data, alpha)\n",
    "\n",
    "print(f\"Exponential Weighted Variance and Std Dev:\")\n",
    "print(f\"  EWVAR: {ewvar_result[-1]:.4f}\")\n",
    "print(f\"  EWSTD: {ewstd_result[-1]:.4f}\")\n",
    "print(f\"\\nComparison with pandas.ewm():\")\n",
    "print(f\"  HPCSeries uses adjust=False (default pandas behavior)\")\n",
    "print(f\"  Matches: pandas.Series(data).ewm(alpha={alpha}, adjust=False).mean()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exponential Weighted Moving Average (alpha=0.1):\n",
      "  Input length:  1000\n",
      "  Output length: 1000\n",
      "  First value:   0.2484 (initialized to first data point)\n",
      "  Last value:    9.8936\n",
      "\n",
      "EWMA vs Rolling Mean:\n",
      "  EWMA:         No NaN values (uses all history)\n",
      "  Rolling Mean: First 49 values are NaN\n"
     ]
    }
   ],
   "source": [
    "# Create a time series with a trend\n",
    "np.random.seed(42)\n",
    "trend = np.linspace(0, 10, 1000)\n",
    "noise = np.random.randn(1000) * 0.5\n",
    "ts_data = trend + noise\n",
    "\n",
    "# Compare different smoothing approaches\n",
    "alpha = 0.1  # Smoothing factor (0.1 = slow/smooth, 0.9 = fast/responsive)\n",
    "\n",
    "# EWMA - tracks trend with exponential weighting\n",
    "ewma_result = hpcs.ewma(ts_data, alpha)\n",
    "\n",
    "# Standard rolling mean for comparison\n",
    "rolling_mean_result = hpcs.rolling_mean(ts_data, window=50)\n",
    "\n",
    "print(f\"Exponential Weighted Moving Average (alpha={alpha}):\")\n",
    "print(f\"  Input length:  {len(ts_data)}\")\n",
    "print(f\"  Output length: {len(ewma_result)}\")\n",
    "print(f\"  First value:   {ewma_result[0]:.4f} (initialized to first data point)\")\n",
    "print(f\"  Last value:    {ewma_result[-1]:.4f}\")\n",
    "print(f\"\\nEWMA vs Rolling Mean:\")\n",
    "print(f\"  EWMA:         No NaN values (uses all history)\")\n",
    "print(f\"  Rolling Mean: First {49} values are NaN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exponential Weighted Statistics (NEW in v0.8)\n",
    "\n",
    "Exponential weighted statistics give more weight to recent observations, making them ideal for tracking trends in time series data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Explore more advanced features:\n",
    "\n",
    "1. **01_rolling_mean_vs_median.ipynb** - Rolling window operations\n",
    "2. **02_robust_anomaly_climate.ipynb** - Anomaly detection with robust statistics\n",
    "3. **03_batched_iot_rolling.ipynb** - Batched processing for IoT data\n",
    "4. **04_axis_reductions_column_stats.ipynb** - 2D array operations\n",
    "5. **05_masked_missing_data.ipynb** - Handling missing data\n",
    "6. **06_performance_calibration.ipynb** - Performance tuning and optimization\n",
    "7. **07_c_optimized_operations.ipynb** - C-accelerated operations (v0.7)\n",
    "\n",
    "## Documentation\n",
    "\n",
    "- **GitHub**: [HPCSeries Core Repository](https://github.com/yourusername/HPCSeriesCore)\n",
    "- **API Reference**: See `docs/` directory\n",
    "- **Specifications**: See root directory for detailed specs\n",
    "\n",
    "## Support\n",
    "\n",
    "For issues, questions, or contributions, please visit the GitHub repository."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
